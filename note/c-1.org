1# The acts of the mind, wherein it exerts its power over simple
ideas, are chiefly these three: 
 1. Combining several simple ideas into one compound one, and thus all
    complex ideas are made.
 2. The second is bringing two ideas, whether simple or complex,
    together, and setting them by one another so as to take a view of
    them at once, without using them into one, by which it gets all
    its ideas of relations.
 3. The third is separating them from all other ideas that accompany
    them in their real existence: this is called abstraction, and thus
    all its general ideas are made.
---- John Locke, An Essay Concerning Human Understanding

2# The most significant of these features is the fact that Lisp
descriptions of processes, called procedures, can themselves be
represented and manipulated as Lisp data. The importance of this is
that there are powerful program-design techniques that rely on the
ability to blur the traditional distinction between "passive" data and
"active" processes.

* 1.1 The Elements of Programming
1# A power programming language is more than just a means of
instructing a computer to perform tasks. The language also serves as a
framework with which we organize our ideas about processes. Thus, when
we describe a language, we should pay particular attention to the
means that the language provides for combining simple ideas to form
complex ideas. Every powerful language has three mechanisms for
accomplishing this:
 1. primitive expressions, which represents the simplest entities the
    language is concerned with,
 2. means of combination, by which compound elements are built from
    simpler one, and
 3. means of abstraction, by which compound elements can be named and
    manipulated as units
Thus, any powerful programming language should be able to describe
primitive data and primitive procedures and should have methods for
combining and abstracting procedures and data.

2# A critical aspect of a programming language is the means it
provides for using names to refer to computational objects. We say
that the name identifies a variable whose value is the object. It
should be clear that the possibility of associating values with
symbols and later retrieving them means that the interpreter must
maintain some sort of memory that keeps track of the name-object
pairs. This memory is called the environment.

3# Note the role of the environment in determining the meaning of the
symbols in expressions.

4# Special forms introduced: define, if, cond, and, or.

5# Substitution model: to apply a compound procedure to arguments,
evaluate the body of the procedure with each formal parameters
replaced by the corresponding argument.

6# Applicative order vs Normal order: "fully expand and then reduce"
evaluation method is known as normal-order evaluation, in contrast to
the "evaluate the arguments and then apply" method that the
interpreter actually uses, which is called applicative-order
evaluation.

7# (cond (<p1> <e1>)
         (<p2> <e2>)
	 ...
	 (<pn> <pn>))

   (if (predicate) <consequence> <alternative>)

Notice: The <e> part of each cond clause may be a sequence of
expressions. In an if expression, however, the <consequence> and
<alternative> must be single expressions.

8# Procedures as black-box abstractions: it is crucial that each
procedure accomplishes an identifiable task that can be used as module
in defining other procedures and we can ignore the detail of how this
procedure computes its result.

9# bound variable vs free variable: 
 1. The set of expressions for which a binding defines a name
    is called the scope of that name.
 2. The meaning of a procedure definition is unchanged if a bound
    variable if consistently renamed throughout the definition.
 3. The meaning of a procedure definition is not independent of the
    names of its free variables, however.

10# Internal definitions and block structure.

11# Particularly Interesting Exercises:
 1. Exercise 1.5: illustrate the differences between normal-order and
    applicative-order evaluation.
 2. Exercise 1.6: why if needs to be provided as a special form.
 3. Exercise 1.7: how to define a good good-enough? like function.

* 1.2 Procedures and the Processes They Generate
1# The "iterative process and recursive process" key words used in
this text are kind of depend on the implementation of recursive
procedure. This is my understanding.

2# The ability to visualize the consequences of the actions under
consideration is crucial to becoming an expert programmer, just as in
any synthetic, creative activity. To become experts, we must learn to
visualize the processes generated by various types of procedures.

3# A procedure is a pattern for the local evolution of a computational
process. It specifies how each stage of the process is built upon the
previous stage.

4# Linear recursion and iteration:
 1. Linear recursion: require the interpreter keep track of the
    operations to be performed later on. O(n) time O(n) space.
 2. Linear iteration: the state can be summarized by a fixed number of
    state variables, together with a fixed rule that describes how the
    state variables should be updated as the process moves from state
    to state and an(optional) end test that specifies conditions under
    which the process should terminate. O(n) time O(1) space.
 3. view from another way: In the iterative case, the program
    variables provide a complete description of the state of the
    process at any point. If we stopped the computation between two
    steps, all we would need to do to resume the computation if to
    supply the interpreter with the values of these program
    variables. Not so with the recursive process. In this case there
    is some additional "hidden" information, maintained by the
    interpreter and not contained in the program variables,  which
    indicates "where the process is" in negotiating the chain of
    deferred operations. The longer the chain, the more information
    must be maintained.
 4. In contracting iteration and recursion, we must be careful not to
    confuse the notion of recursive process with the notion of
    recursive procedure. When we describe a procedure as recursive, we
    are referring to the syntactic fact that the procedure definition
    refers(directly of indirectly) to the procedure itself. But when
    we describe a process as following a pattern that is, say,
    linearly recursive, we are speaking about how the process evolves,
    not about the syntax of how a procedure is written.
 5. One reason that the distinction between process and procedure may
    be confusing is that most implementation of common
    languages(including Ada, Pascal, C) are designed is such a way
    that the interpretation of any recursive procedure consumes an
    amount of memory that grows with the number of procedure calls,
    even when the process described is, in principle, iterative.
 6. Tail-recursive implementation: execute an iterative process in
    constant space, even if the iterative process is described by a
    recursive procedure.    

5# Tree recursion: 
 1. In general, the number of steps required by a tree-recursive
    process will be proportional to the number of nodes in the tree,
    while the space required will be proportional to the maximum depth
    of the tree.

6# Memorization: remember what have been computed, don't repeat
compute them again. 

7# probabilistic methods

8# Interesting examples: 
 1. counting change: elegant solution, beautiful attacking strategy.
 2. exponentiation: be widely used in other places.
 3. testing for primality: seen many times, solved elegant here.

9# Interesting exercises: 
 1. Exercise 1.10: exercise mind, at least for me
 2. Exercise 1.16: In general, the technique of defining an invariant
    quantity that remains unchanged from state to state is s powerful
    way to think about the design of iterative algorithms.
 3. Exercise 1.19: logarithmic algorithm for computing Fibonacci
    numbers
 4. Exercise 2.25: to use a property/rule/law at different times has
    different consequences 
 5. Exercise 2.26: to me, it illustrate how to use procedure with
    parameters to avoid repeated computation.
 6. Exercise 2.28: Miller-Rabin test for primality, which takes care
    of Carmichael numbers.

* 1.3 Formulating Abstractions with Higher-Order Procedures
1# Often the same programming pattern will be used with a number of
different procedures. To express such patterns as concepts, we will
need to construct procedures that can accept procedures as arguments
or return procedures as values. Procedures that manipulate procedures
are called higher-order procedures.

2# special forms introduced:
 1. lambda: (lambda (<formal-parameters>) <body>)
 2. let: (let ((<var1> <exp1>)
               (<var2> <exp2>)
               ...
               (<varn> <expn>))
             <body>)
 3. '2.' is equal to:
 ((lambda (<var1> ... <varn>)
   <body>)
 <exp1>
 ...
 <expn>)
 A let expression is simply syntactic sugar for the underlying
 lambda application.
 4. The variables' values are computed outside the let.

3# fixed point: A number of x is called a fixed point of a function of
f if x satisfies the equation f(x) = x.

4# average damping: The approach of averaging successive
approximations to a solution, a technique that we call average
damping, often aids the convergence of fixed-pointed searches.

5# In general, there are many ways to formulate a process as a
procedure. Experienced programmers know how to choose procedural
formulations that are particular perspicuous, and where useful
elements of the process are exposed as separate entities that can be
reused in other applications. 

5# As programmers, we should be alert to opportunities to identify the
underlying abstractions in our programs, and to build upon then and
generalize them to create more powerful abstractions. This is not to
say that one should always write programs in the most abstract way
possible; expert programmers know how to choose the level of
abstraction appropriate to their task. But it is important to be able
to think in terms of these abstractions, so that we can be ready to
apply them in new contexts. The significance of higher-order
procedures is that they enable us to represent these abstractions
explicitly as elements in our programming language., so that they can
be handled just like other computational elements.

6# In general, programming languages impose restrictions on the ways
in which computational elements can be manipulated. Elements with the
fewest restrictions are said to have first-class status. Some of the
"rights and privileges" of first-class elements are:
 1. They may be named by variables.
 2. They may be passed as arguments to procedures.
 3. They may be returned as the results of procedures.
 4. They may be included in data structures.

7# Interesting Examples:
 1. (sum term a next b)
 2. (search f neg-point pos-point)
 3. (fixed-point f first-guess)
 4. Newton's method: (derive g) (newton-transform g)
 5. (fixed-point-of-transform g transform guess)

8# Interesting Exercises: 
 1. Exercise 1.32: (accumulate combiner null-value term a next b),
    a more higher-lever procedure.
 2. Exercise 1.33: (filtered-accumulate), an even more general version
    of accumulate.
 3. Exercise 1.34: test understanding of difference between procedural
    object and number.
 4. Exercise 1.41: double-double-double, wow!
 5. Exercise 1.42: (compose f g) -> f(g(x))
 6. Exercise 1.43: (repeat f n) -> f(f(f(...f(x))))
 7. Exercise 1.45: the number of average-damping needed to avoid
    oscillation.
 8. Exercise 1.46: (iterative-improve good-enough? improve) -> f(guess)
