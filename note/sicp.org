* Foreword and Preface
1# " think that it's extraordinarily important that we in computer
science keep fun in computing. When it started out, it was awful lot
of fun. Of course, the paying customers  got shafted every now and
then, and after a while we began to take their complaints
seriously. We began to feel as if we really were responsible for the
successful, error-free perfect use of these machines. I don't think we
are. I think we are responsible for stretching them, setting them off
in new directions, and keeping fun in the house. I hope the field of
computer science never loses its sense of fun. Above all, I hope we
don't become missionaries. Don't feel as if you're Bible salesman. The
world has too many of those already. What you know about computing
other people will learn. Don't feel as if the key to successful
computing is only in your hands. What's in your hands, I think and
hope, is intelligence: the ability to see the machine as more than
when you were first led up to it, that you can make it more."
--- Alan J.Perlis

2# To appreciate programming as an intellectual activity in its own
right you must turn to computer programming; you must read and write
computer programs--many of them. It doesn't matter what the programs
are about or what applications they serve. What does matter is how
well they perform and how smoothly they fit with other programs in the
creation of still greater programs. The programmer most seek both
perfection of part and adequacy of collection.

3# Our traffic with the subject matter of this book involves us with
three foci of phenomena: the human mind, collections of computer
programs, and the computer. Every computer program is a model, hatched
in the mind, of a real or mental process. These processes, arising
from human experience and thought, are huge in number, intricate in
detail, and at any time only partially understood. They are modeled to
our permanent satisfaction rarely by our computer programs. Thus even
though our programs are carefully handcrafted discrete collection of
symbols, mosaics of interlocking functions, the continually evolve: we
change them as perception of the model deepens, enlarges, generalizes
until the model ultimately attains a metastable place within still
another model with which we struggle. The source of the exhilaration
associated with computer programming is the continual unfolding within
the mind and on the computer of mechanisms expressed as programs and
the explosion of perception the generate. If art interprets our
dreams, the computer executes them in the guise of programs.

4# Since large programs grow from small ones, it is crucial that we
develop an arsenal of standard program structures of whose correctness
we have become sure--we call them idioms--and learn to combine them
into larger structures using organizational techniques of proven value.

5# More than anything else, the uncovering and mastery of powerful
organizational techniques accelerates our ability to create large,
significant programs.

6# A programmer should acquire good algorithms and idioms. Even though
some programs resist precise specifications, it is the responsibility
of the programmer to estimate, and always to improve, their
performance.

7# After all, the critical programming concerns of software
engineering and artificial intelligence tend to coalesce as the systems
under investigation become larger.

8# Invent and fit; have fits and reinvent!

9# Our design of this introductory computer-science subject reflects
two major concerns. First, we want to establish the idea a computer
programming language is not just a way of getting a computer to
perform operations but rather that it is a novel formal medium for
expressing ideas about methodology. Thus, programs must be written for
people to read, and only incidentally for machines to execute. Second,
we believe that the essential material to be addressed at this level
is not the syntax of particular programming-language constructs, nor
clever algorithms for computing particular functions efficiently, not
even the mathematical analysis of algorithms and the foundations of
computing, but rather the techniques used to control the intellectual
complexity of large software systems.

10# These skills are by no means unique to computer programming. The
techniques we teach and draw upon are common to all of engineering
design. We control complexity building abstractions that hide details
when appropriate. We control complexity by establishing conventional
interfaces that enable us to construct systems by combining standard,
well-understood pieces in a "mix and match" way. we control complexity
by establishing new languages for describing a design, each of which
emphasizes particular aspects of the design and deemphasizes others.

11# Underlying our approach to this subject is our conviction that
"computer science" is not a science and that its significance has
little to do with computers. The computer revolution is a revolution
in the way we think and in the way we express what we think. The
essence if this change is the emerge of that might be called
procedural epistemology--the study of the structure of knowledge from
an imperative point of view, as opposed to the more declarative point
of view taken by classical mathematical subjects. Mathematics provides
a framework for dealing precisely with notions of "what is."
Computation provides a framework for dealing precisely with notions of
"how to."

12# One should avoid complexities of control and concentrate on
organizing the data to reflect the real structure of the world being
modeled.

13# Computation provides a means of expression for exploring ideas
that would be otherwise be too complex to deal with precisely.

* Chapter 1 Building Abstractions with Procedures
1# The acts of the mind, wherein it exerts its power over simple
ideas, are chiefly these three: 
 1. Combining several simple ideas into one compound one, and thus all
    complex ideas are made.
 2. The second is bringing two ideas, whether simple or complex,
    together, and setting them by one another so as to take a view of
    them at once, without using them into one, by which it gets all
    its ideas of relations.
 3. The third is separating them from all other ideas that accompany
    them in their real existence: this is called abstraction, and thus
    all its general ideas are made.
---- John Locke, An Essay Concerning Human Understanding

2# The most significant of these features is the fact that Lisp
descriptions of processes, called procedures, can themselves be
represented and manipulated as Lisp data. The importance of this is
that there are powerful program-design techniques that rely on the
ability to blur the traditional distinction between "passive" data and
"active" processes.

** 1.1 The Elements of Programming
1# A power programming language is more than just a means of
instructing a computer to perform tasks. The language also serves as a
framework with which we organize our ideas about processes. Thus, when
we describe a language, we should pay particular attention to the
means that the language provides for combining simple ideas to form
complex ideas. Every powerful language has three mechanisms for
accomplishing this:
 1. primitive expressions, which represents the simplest entities the
    language is concerned with,
 2. means of combination, by which compound elements are built from
    simpler one, and
 3. means of abstraction, by which compound elements can be named and
    manipulated as units
Thus, any powerful programming language should be able to describe
primitive data and primitive procedures and should have methods for
combining and abstracting procedures and data.

2# A critical aspect of a programming language is the means it
provides for using names to refer to computational objects. We say
that the name identifies a variable whose value is the object. It
should be clear that the possibility of associating values with
symbols and later retrieving them means that the interpreter must
maintain some sort of memory that keeps track of the name-object
pairs. This memory is called the environment.

3# Note the role of the environment in determining the meaning of the
symbols if expressions.

4# Special forms introduced: define, if, cond, and, or.

5# Substitution model: to apply a compound procedure to arguments,
evaluate the body of the procedure with each formal parameters
replaced by the corresponding argument.

6# Applicative order vs Normal order: "fully expand and then reduce"
evaluation method is known as normal-order evaluation, in contrast to
the "evaluate the arguments and then apply" method that the
interpreter actually uses, which is called applicative-order
evaluation.

7# (cond (<p1> <e1>)
         (<p2> <e2>)
	 ...
	 (<pn> <pn>))

   (if (predicate) <consequence> <alternative>)

Notice: The <e> part of each cond clause may be a sequence of
expressions. In an if expression, however, the <consequence> and
<alternative> must be single expressions.

8# Procedures as black-box abstractions: it is crucial that each
procedure accomplishes an identifiable task that can be used as module
in defining other procedures and we can ignore the detail of how this
procedure computes its result.

9# bound variable vs free variable: 
 1. The set of expressions for which a binding variable defines a name
    is called the scope of that name.
 2. The meaning of a procedure definition is unchanged if a bound
    variable if consistently renamed throughout the definition.
 3. The meaning of a procedure definition is not independent of the
    names of its free variables, however.

10# Internal definitions and block structure.

11# Particularly Interesting Exercises:
 1. Exercise 1.5: illustrate the differences between normal-order and
    applicative-order evaluation.
 2. Exercise 1.6: why if needs to be provided as a special form.
 3. Exercise 1.7: how to define a good good-enough? like function.

** 1.2 Procedures and the Processes They Generate
1# The "iterative process and recursive process" key words used in
this text are kind of depend on the implementation of recursive
procedure. This is my understanding.

2# The ability to visualize the consequences of the actions under
consideration is crucial to becoming an expert programmer, just as in
any synthetic, creative activity. To become experts, we must learn to
visualize the processes generated by various types of procedures.

3# A procedure is a pattern for the local evolution of a computational
process. It specifies how each stage of the process is built upon the
previous stage.

4# Linear recursion and iteration:
 1. Linear recursion: require the interpreter keep track of the
    operations to be performed later on. O(n) time O(n) space.
 2. Linear iteration: the state can be summarized by a fixed number of
    state variables, together with a fixed rule that describes how the
    state variables should be updated as the process moves from state
    to state and an(optional) end test that specifies conditions under
    which the process should terminate. O(n) time O(1) space.
 3. view from another way: In the iterative case, the program
    variables provide a complete description of the state of the
    process at any point. If we stopped the computation between two
    steps, all we would need to do to resume the computation if to
    supply the interpreter with the values of these program
    variables. Not so with the recursive process. In this case there
    is some additional "hidden" information, maintained by the
    interpreter and not contained in the program variables,  which
    indicates "where the process is" in negotiating the chain of
    deferred operations. The longer the chain, the more information
    must be maintained.
 4. In contracting iteration and recursion, we must be careful not to
    confuse the notion of recursive process with the notion of
    recursive procedure. When we describe a procedure as recursive, we
    are referring to the syntactic fact that the procedure definition
    refers(directly of indirectly) to the procedure itself. But when
    we describe a process as following a pattern that is, say,
    linearly recursive, we are speaking about how the process evolves,
    not about the syntax of how a procedure is written.
 5. One reason that the distinction between process and procedure may
    be confusing is that most implementation of common
    languages(including Ada, Pascal, C) are designed is such a way
    that the interpretation of any recursive procedure consumes an
    amount of memory that grows with the number of procedure calls,
    even when the process described is, in principle, iterative.
 6. Tail-recursive implementation: execute an iterative process in
    constant space, even if the iterative process is described by a
    recursive procedure.    

5# Tree recursion: 
 1. In general, the number of steps required by a tree-recursive
    process will be proportional to the number of nodes in the tree,
    while the space required will be proportional to the maximum depth
    of the tree.

6# Memorization: remember what have been computed, don't repeat
compute them again. 

7# probabilistic methods

8# Interesting examples: 
 1. counting change: elegant solution, beautiful attacking strategy.
 2. exponentiation: be widely used in other places.
 3. testing for primality: seen many times, solved elegant here.

9# Interesting exercises: 
 1. Exercise 1.10: exercise mind, at least for me
 2. Exercise 1.16: In general, the technique of defining an invariant
    quantity that remains unchanged from state to state is s powerful
    way to think about the design of iterative algorithms.
 3. Exercise 1.19: logarithmic algorithm for computing Fibonacci
    numbers
 4. Exercise 2.25: to use a property/rule/law at different times has
    different consequences 
 5. Exercise 2.26: to me, it illustrate how to use procedure with
    parameters to avoid repeated computation.
 6. Exercise 2.28: Miller-Rabin test for primality, which takes care
    of Carmichael numbers.

** 1.3 Formulating Abstractions with Higher-Order Procedures
1# Often the same programming pattern will be used with a number of
different procedures. To express such patterns as concepts, we will
need to construct procedures that can accept procedures as arguments
or return procedures as values. Procedures that manipulate procedures
are called higher-order procedures.

2# special forms introduced:
 1. lambda: (lambda (<formal-parameters>) <body>)
 2. let: (let ((<var1> <exp1>)
               (<var2> <exp2>)
               ...
               (<varn> <expn>))
             <body>)
 3. '2.' is equal to:
 ((lambda (<var1> ... <varn>)
   <body>)
 <exp1>
 ...
 <expn>)
 A let expression is simply syntactic sugar for the underlying
 lambda application.
 4. The variables' values are computed outside the let.

3# fixed point: A number of x is called a fixed point of a function of
f if x satisfies the equation f(x) = x.

4# average damping: The approach of averaging successive
approximations to a solution, a technique that we call average
damping, often aids the convergence of fixed-pointed searches.

5# In general, there are many ways to formulate a process as a
procedure. Experienced programmers know how to choose procedural
formulations that are particular perspicuous, and where useful
elements of the process are exposed as separate entities that can be
reused in other applications. 

5# As programmers, we should be alert to opportunities to identify the
underlying abstractions in our programs, and to build upon then and
generalize them to create more powerful abstractions. This is not to
say that one should always write programs in the most abstract way
possible; expert programmers know how to choose the level of
abstraction appropriate to their task. But it is important to be able
to think in terms of these abstractions, so that we can be ready to
apply them in new contexts. The significance of higher-order
procedures is that they enable us to represent these abstractions
explicitly as elements in our programming language., so that they can
be handled just like other computational elements.

6# In general, programming languages impose restrictions on the ways
in which computational elements can be manipulated. Elements with the
fewest restrictions are said to have first-class status. Some of the
"rights and privileges" of first-class elements are:
 1. They may be named by variables.
 2. They may be passed as arguments to procedures.
 3. They may be returned as the results of procedures.
 4. They may be included in data structures.

7# Interesting Examples:
 1. (sum term a next b)
 2. (search f neg-point pos-point)
 3. (fixed-point f first-guess)
 4. Newton's method: (derive g) (newton-transform g)
 5. (fixed-point-of-transform g transform guess)

8# Interesting Exercises: 
 1. Exercise 1.32: (accumulate combiner null-value term a next b),
    a more higher-lever procedure.
 2. Exercise 1.33: (filtered-accumulate), an even more general version
    of accumulate.
 3. Exercise 1.34: test understanding of difference between procedural
    object and number.
 4. Exercise 1.41: double-double-double, wow!
 5. Exercise 1.42: (compose f g) -> f(g(x))
 6. Exercise 1.43: (repeat f n) -> f(f(f(...f(x))))
 7. Exercise 1.45: the number of average-damping needed to avoid
    oscillation.
 8. Exercise 1.46: (iterative-improve good-enough? improve) -> f(guess)

* Chapter 2 Building Abstractions with Data
1# Why do we want compound data in a programming language? For the
same reason that we want compound procedures: to elevate the
conceptual level at which we can design our programs, to increase the
modularity of our designs, and to enhance the expressive power of our
language. Just as the ability to define procedures enables us to deal
with processes at a higher conceptual level than that of the primitive
operations of the language, the ability to construct compound data
objects enables us to deal with data at a higher conceptual level than
that of the primitive data objects of the language.

2# The general technique of isolating the parts of a program that deal
with how data objects are represented from the parts of a program that
deal with how data objects are used is a powerful design methodology
called data abstraction. 

3# One key idea in dealing with compound data is the notion of
closure--that the glue we use for combining data objects should allow
us to combine not only primitive data objects, but compound data
objects as well. Another key idea is that compound data objects can
serve as conventional interface for combining program modules in
mix-and-match ways. 

4# We will find that, just as a given numerical function can be
computed by many different computational processes, there are many
ways in which a given data structure can be represented in terms of
simpler objects, and the choice of representation can have significant
impact on the time and space requirements of processes that manipulate
the data.

** 2.1 Introduction to Data Abstraction
1# That is, the details of how the procedure was implemented could be
suppressed, and the particular procedure itself could be replaced by
any other procedure with the same overall behavior. In other words, we
could make an abstraction that would separate the way the procedure
would be used from the details of how the procedure would be
implemented in the terms of more primitive procedures. The analogous
notion for compound data is called data abstraction. Data abstraction
is a methodology that enables us to isolate how a compound data object
is used from the details of how it is constructed from more primitive
data objects.

2# Our programs should use data in such a way as to make no
assumptions about the data that are not strictly necessary for
performing the task at hand. At the same time, a "concrete" data
representation is defined independent of the programs that use the
data. The interface between these two parts of our system will be a
set of procedures, called selectors and constructors, that implement
the abstract data in terms of the concrete representation.

3# We are using here a powerful strategy of synthesis: wishful thinking.

4# In general, the underlying idea of data abstraction is to identify
for each type of data a basic set of operations in terms of which all
manipulations of data objects of that type will be expressed, and then
to use only those operations in manipulating the data.

5# Constraining the dependence on the representation to a few
interface procedures helps us design programs as well as modify them,
because it allow us to maintain the flexibility to consider alternate
implementations. 

6# In general, we can think of data as defined by some collection of
selectors and constructors, together with specified conditions that
these procedures must fulfill in order to be a valid representation.

7# This example(p86) also demonstrates that the ability to manipulate
procedures as objects automatically provides the ability to represent
compound data. This may seem curiosity now, but procedural
representation of data will play a central role in our programming
repertoire. 

8# Interesting Examples: 
 1. rational number: simple and elegant.
 2. (p86)procedural representation of data: cool, never seen this
    before.
 3. interval arithmetic: never think about this kind of problem
    before, good example.

9# Interesting Exercises:
 1. Exercise 2.4: still procedural representation of data.
 2. Exercise 2.6: wow, procedural arithmetic.
 3. Exercise 2.16: Understanding the underlying differences between
    interval arithmetic and exact-number arithmetic, some of the basic
    laws/rules we take for granted are no longer valid for interval
    arithmetic.

** 2.2 Hierarchical Data and the Closure Property
1# In general, an operation for combining data objects satisfies the
closure property if the results of combining things with that
operation can themselves be combined using the same operation.

2# Be careful not to confuse the expression (list 1 2 3 4) with the
list (1 2 3 4), which is the result obtained when the expression is
evaluated. Attempting to evaluate the expression (1 2 3 4) will signal
an error when the interpreter tries to apply 1 to the arguments 2, 3,
and 4. 

3# sequence as conventional interface:
 1. The use of pairs to represent sequences of elements as lists is
    accompanied by conventional programming techniques for
    manipulating lists by successively "cdring down" the lists.
 2. Another conventional programming technique is to "cons up" an
    answer list while cdring down a list.
 3. (p105)Our two procedures decompose the computations in a different
    way, spreading the enumeration over the program and mingling it
    with the map, the filter, and the accumulation. If we could
    organize our programs to make the signal-flow structure manifest
    in the procedures we write, this would increase the conceptual
    clarity of the resulting code. The key to organizing programs so
    as to more clearly reflect the signal-flow structure is to
    concentrate on the "signals" that flow from one stage in the
    process to the next. If we represent these signals as lists, then
    we can use list operations to implement the processing at each of
    the stages.
 4. The value of expressing programs as sequence operations is that
    this helps us make program designs that are modular, that is,
    designs that are constructed by combining relatively independent
    pieces.
 5. Sequences, implemented here as lists, serve as a conventional
    interface that permits to combine processing
    modules. Additionally, when we represent structures as sequences,
    we have localized the data-structure dependencies in our programs
    to a small number of sequence operations.

4# Map is an important construct, not only because it captures a
common pattern, but because it establishes a higher level of
abstraction in dealing with lists. In the original definition of
scale-list, the recursive structure of the program draws attention to
the element-by-element processing of the list. Defining scale-list in
terms of map suppresses that level of detail and emphasizes that
scaling transforms a list of elements to a list of results. The
difference between the two definitions is not that the computer is
performing a different process(it isn't) but that we think about the
process differently. In effect, map helps establish an abstraction
barrier that isolates the implementation of procedures that transform
list from the details of how the elements of the list are extracted
and combined. This abstraction gives us the flexibility to change the
low-level details of how sequences are implemented, while preserving
the conceptual framework of operations that transform sequences to
sequences. 

5# We will implement the painter operations as procedures. This means
that we don't need a special abstraction mechanism in the picture
language: Since the means of combination are ordinary procedures, we
automatically have the capability to do anything with painter
operations that we can do with procedures.

6# In addition to abstracting patterns of combining painters, we can
work at a higher level, abstracting patterns of combining painter
operations.

7# stratified design: the notation that a complex system should be
structured as a sequence of levels that are described using a sequence
of languages. Each level is constructed by combing parts that are
regarded as primitive at that level, and the parts constructed at each
level are used as primitives at the next level. The languages used at
each level of a stratified design has primitives, means of
combination, and means of abstraction appropriate to that level of
detail.

 1. Stratified design helps make programs robust, that is, it makes it
    likely that small changes in a specification will require
    correspondingly small changes in the program.
 2. In general, each level of a stratified design provides a different
    vocabulary for expressing the characteristics of the system, and a
    different kind of ability to change it.

8# Interesting Examples: 
 1. (list <a1> <a2> ... <an>) is equivalent to:
    (cons <a1> (cons <a2> (cons ... (cons <an> nil) ... )))
 2. map over lists, map over trees
 3. accumulate, flatmap--(accumulate append nil map)
 4. permutations using nested mappings
 5. Picture Language:
  1>. frame coordination map: unit square to frame square
  2>. transform painter: transforms the frame and calls the original
  painter on the transformed frame.

9# Interesting Exercises:
 1. Exercise 2.18: feel the differences between iterative and
    recursive implementation: I think the iterative one is bottom-up
    method, while the recursive one is a top-down method. By using the
    iterative implementation, we first get the "nil" value as the
    initial result, then we increase the partial result at each step
    until we reach the final result. By using the recursive
    implementation, we first assume that we've gotten a partial result
    and then combine the partial result with what we get at this
    current step to get the final result. 
 2. Exercise 2.20: dotted-tail notation, for arbitrary numbers of
    arguments.
 3. Exercise 2.22: "kind of like 2.18", focus more specifically the
    differences between 'cons' and 'append'.
 4. Exercise 2.27: deep-reverse, cool! Think hierarchically. 
 5. Exercise 2.29: still find it hard to think hierarchically.
 6. Exercise 2.31: tree-map, interesting recursive pattern.
 7. Exercise 2.32: subsets.
 8. Exercise 2.33: use accumulate to implement map, append, and
    length.
 9. Exercise 2.35: still that interesting tree recursive pattern.
 10. Exercise 2.36: simpler than thought, but interesting.
 11. Exercise 2.37: how to solve hard problem by building a solution
     based on the previous work.
 12. Exercise 2.38: as intuition tells me, fold-left is easier to
     implement using iterative process, while fold-right is easier to
     implement using recursive process.
 13. Exercise 2.39: interesting, have not thought about this
     before. have not thought that deep.
 14. Exercise 2.42: eight-queens puzzle 
 15. Exercise 2.42: little change, huge efficiency effect.
